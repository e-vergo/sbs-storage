# Session Retrospective: DuckDB + Oracle Evolution

**Date:** 2026-02-04
**Session ID:** 1770206754
**Issues:** #118 (DuckDB Query Layer), #128 (Oracle Evolution)
**PR:** #171 (merged via squash)

---

## Session Summary

This session implemented two connected issues in sequence:

1. **#118 (DuckDB Query Layer):** Replaced all imperative Python analytics with a DuckDB-backed query layer
2. **#128 (Oracle Evolution):** Migrated `/oracle` skill to `ask_oracle` MCP tool, consolidating oracle query interfaces

**Key Metrics:**
- 4 waves, single-agent sequential execution
- PR #171 created, merged (squash)
- Net: +3,779 / -3,582 lines across 22 files
- 144/144 MCP tests pass, 725/725 evergreen tests pass
- Deleted `sbs_self_improve.py` (1,670 lines)
- Eliminated `load_archive_index()` from all 27 call sites
- Deleted `/oracle` skill, replaced `sbs_oracle_query` with `ask_oracle`

---

## Analysis Dimensions

### 1. User Orchestration

**Decisiveness and Clarity:**
The user was exceptionally clear throughout alignment:
- "Both in sequence" (scope decision)
- "Full replacement" (migration strategy)
- "Lifespan-scoped" (DB lifecycle model)
- "Replace entirely" (oracle query consolidation)

**Key Course Correction:**
User explicitly rejected partial migration during alignment: *"doing things halfway in any way shape or form will cause a mess down the line"*. This changed the plan from leaving `load_archive_index()` for non-analytics tools to full unification of all 27 call sites. This was the right call — leaving dual code paths would have created long-term technical debt.

**Efficient Q&A:**
Three rounds of `AskUserQuestion` during alignment were effective. Each round clarified a distinct decision dimension without redundancy:
1. Scope (both issues vs. just #118)
2. Migration strategy (full replacement vs. incremental)
3. DB lifecycle + oracle architecture

**Clarification Example:**
User provided the "rich context tool" clarification for oracle architecture when the agent-spawning question options didn't capture the actual pattern used in the codebase.

### 2. Claude Alignment

**Significant Gap in Initial Plan:**
The original plan proposed keeping `load_archive_index()` for non-analytics tools as "future work." The user caught this immediately. This was a failure to internalize the user's stated goal of "one central data system." The alignment phase should have identified this earlier — the question about migration strategy should have explicitly addressed all 27 call sites, not just analytics tools.

**Misunderstanding of Codebase Pattern:**
The question about whether MCP tools "deploy agents" revealed confusion about the codebase's context injection pattern. The exploration correctly identified that tools like `/task` inject oracle context via `sbs_context()`, but the multiple-choice options didn't include "rich context tool" as an answer. The user selected "Other" effectively, which worked but indicated the question was poorly framed.

**Overall Alignment Quality:**
Despite the two issues above, alignment phase worked well:
- 3 question rounds covered all critical dimensions
- User corrections were incorporated immediately
- No mid-execution surprises or scope creep

### 3. System Design

**DuckDB Integration Success:**
- No dependency conflicts (DuckDB is pure-Python for the wheels we're using)
- In-memory DB fits the MCP server lifespan model perfectly
- SQL window functions replaced 120 lines of imperative Python for session grouping
- Query performance is excellent (no noticeable latency on 300+ entry archives)

**Architectural Observations:**

1. **File Size:**
   `duckdb_layer.py` at 2,200 lines is large. Future consideration: split into `duckdb_schema.py` (table creation, loading) and `duckdb_queries.py` (analytics methods). However, the current structure groups by responsibility (schema vs. queries) within the file, so this may not be urgent.

2. **Session Grouping Complexity:**
   SQL window functions worked well but required a two-CTE approach due to DuckDB's restriction on nested window functions. The resulting query is more declarative than the original Python but harder to debug if it breaks.

3. **Cache Invalidation:**
   The `invalidate()` pattern for post-write cache busting is clean but relies on callers remembering to call it. A decorator or context manager pattern could enforce this automatically. Example risk: a new archive-writing tool forgets to call `invalidate()`, and stale data persists until MCP server restart.

4. **Oracle Format Coupling:**
   Oracle concept index in `sbs-oracle.md` is now load-bearing for DuckDB parsing. Changes to the markdown table format will break `_load_oracle_data()`. This coupling should be documented explicitly in the oracle regeneration workflow.

**Test Coverage:**
51 new DuckDB tests provide excellent coverage of the query layer itself. However, these test the DuckDB layer in isolation, not the integration path from `sbs_tools.py` through to DuckDB. The integration is tested only indirectly via existing archive/skill tests. This is acceptable but worth noting.

### 4. Plan Execution

**Wave-by-Wave Breakdown:**

| Wave | Focus | LOC Change | Outcome |
|------|-------|------------|---------|
| 1 | Foundation | +2,200 (new), +500 (tests) | DuckDB layer + schema + tests |
| 2 | Migration | -1,670 (`sbs_self_improve.py`), 27 call sites | Full unification |
| 3 | Documentation | 9 files updated | Removed stale `/oracle` refs |
| 4 | Verification | 0 (tests only) | 144/144 MCP, 725/725 evergreen |

**Execution Quality:**
- All 4 waves executed exactly as planned — no mid-flight adjustments needed
- Wave 1 was the heaviest lift but had no blockers
- Wave 2 was the most surgical: 27 call sites changed cleanly
- Wave 3 caught stale references in skills, agents, docs, and CLAUDE.md
- Wave 4 confirmed zero regressions

**Sequential Necessity:**
Sequential waves were required due to `sbs_tools.py` file overlap between waves 2 and 3. Parallel execution would have caused merge conflicts.

### 5. Meta-Observations

**Bootstrapping Paradox:**
The archive system itself is still running on the old code path during this session (DuckDB changes are merged but the running MCP server hasn't restarted). The next session will be the first to use DuckDB for archive reads. This creates a one-session bootstrap delay where the changes are in `main` but not yet live in the orchestrator's runtime.

**Load-Bearing Format:**
Oracle concept index format in `sbs-oracle.md` is now load-bearing for DuckDB parsing. If the markdown table format changes (e.g., different column names, different separator), `_load_oracle_data()` will break silently. This coupling should be:
1. Documented in the oracle regeneration workflow
2. Tested via a schema validation check in DuckDB tests

**Test Coverage Gap:**
The 51 new DuckDB tests cover the query layer thoroughly, but they test the DuckDB layer in isolation. The integration path from tool registration in `sbs_tools.py` → MCP tool handler → DuckDB is tested only by existing archive/skill tests. This is acceptable because those tests exercise the full stack, but it means:
- A regression in the tool registration wiring wouldn't be caught by DuckDB tests alone
- The `sbs_run_tests(repo="mcp")` gate proved valuable during Wave 2 for catching integration issues

**Code Deletion as Success Metric:**
Deleting `sbs_self_improve.py` (1,670 lines) felt like a major win. The file had grown organically over time and was hard to maintain. Replacing it with declarative SQL queries is a clear improvement in readability and debuggability.

**Oracle Evolution Impact:**
The shift from `/oracle` skill to `ask_oracle` MCP tool is subtle but significant:
- **Before:** Oracle queries were a "special activity" requiring a skill invocation
- **After:** Oracle queries are just another tool call, usable inline during any task
- This reduces friction for agents and users who just want a quick file location or concept lookup

---

## Conclusion

This session successfully replaced a 1,670-line imperative analytics system with a declarative DuckDB query layer, and consolidated oracle query interfaces into a single MCP tool. The work was clean, well-structured, and introduced zero regressions.

**Key Takeaway:**
User decisiveness ("full replacement, no halfway") was the critical factor in avoiding technical debt. The initial plan's gap (leaving `load_archive_index()` as future work) would have created a bifurcated data access pattern. The user's course correction prevented this.

**Future Considerations:**
1. Document oracle format coupling in regeneration workflow
2. Consider splitting `duckdb_layer.py` if it grows beyond 3,000 lines
3. Monitor cache invalidation pattern for correctness as new tools are added
4. Verify next session uses DuckDB successfully (bootstrap delay)
