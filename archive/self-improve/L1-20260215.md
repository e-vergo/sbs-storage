# L1 Introspection Finding -- Feb 15, 2026

## Synthesis Context
- Level: L1
- L0 documents analyzed: 5
  - L0-20260209000953.md (Feb 8 epoch, first pass)
  - L0-20260209001854.md (Feb 8 epoch, refinement pass)
  - L0-20260215-cluster-feb8.md (Feb 8 epoch, third pass with quantitative precision)
  - L0-20260215-cluster-feb9-14.md (5-day quiescent period)
  - L0-20260215-cluster-feb15.md (Feb 15 active sessions)
- Period covered: Feb 8-15, 2026
- Previous L1: Feb 9, 2026 (L1-20260209002147.md)
- Improvement captures analyzed: 20 total (12 from Feb 8 cluster, 5 from Feb 9-14 quiescent period, 1 from Feb 15, plus overlap with the 20 from the Feb 8 epoch)
- Issues correlated: #284-#295 (all closed), #343-#347 (all closed)
- New issues logged this L0 cycle: #343, #344, #345, #346, #347

## Cross-Session Patterns

### Recurring Error Classes

1. **Documentation-without-enforcement failures (persistent, 3 epochs)**

   The most consistent error class across this entire period. Lessons get documented in CLAUDE.md but compliance remains at 0% without tooling enforcement. The oracle-first protocol is the canonical example: documented Feb 8, issue #285 logged Feb 9, 100% violation rate through Feb 15 (three consecutive epochs). The previous L1 identified this pattern; it has only strengthened since.

   Additional instances from this period:
   - MCP-first for builds (#345): documented, agents still use bash
   - Orchestrator plan approval (#343): documented, orchestrator still calls skill lifecycle directly
   - Agent block-wait: the ONE success story -- documented AND behavioral change stuck, now at 0% violation

   The block-wait success is the control case. What made it different? Three captures across three separate sessions (the "triple-capture" pattern, #290) plus immediate, repeated failure consequences (lost sync, dead time). The oracle-first protocol has no immediate failure consequence -- agents that skip it still produce results, just more slowly. This suggests enforcement is necessary specifically for protocols where violation is painless in the short term but costly in aggregate.

2. **Tagger signal contamination (persistent, worsening)**

   The tagger's session-level evaluation creates false positives across three dimensions:
   - Within an epoch: all entries get identical tags (#287)
   - Across temporal boundaries: idle entries days later inherit session tags (L0-feb9-14, Finding 2)
   - Across task boundaries: a 33-second clean operation inherits 11-hour session friction tags (#347)

   This was identified in the previous L1 as "observation system blind spots at two scales." The Feb 15 L0 added a third scale (cross-task leakage). The problem is worsening because as more diverse operations run within single Claude Code sessions, more contamination occurs.

3. **Scope expansion in long sessions (confirmed pattern)**

   The Feb 15 Task 1 ran 11 hours -- the longest task observed to date. It started `scope:narrow` but expanded mid-flight. The Feb 8 epoch was 48 entries with 20 improvement captures. Both validate #295's concerns about session scope control.

   Velocity data reinforces this: Feb 8 showed 23min vs 3h28m task asymmetry; well-scoped tasks complete 9x faster. Long sessions correlate with scope drift, context compaction, and tagger saturation simultaneously.

4. **Recursive/nested workflow invocations (#344)**

   A new error class discovered Feb 15: agents within a running `sls_task` can invoke `sls_task` again, corrupting global_state. The guard was intended for crash recovery but permits nested invocation. This is a latent bug that becomes more likely as session complexity increases -- precisely the trend we're observing.

### Common Friction Points

1. **Oracle coverage gaps as a root cause, not just a symptom**

   L0-feb9-14 Finding 5 identified that `vscode-lean4` and `LeanArchitect RPC` aren't indexed in the oracle. This means agents aren't just lazily skipping the oracle -- the oracle genuinely cannot answer some of their queries. The 100% oracle-first violation rate likely reflects both behavioral non-compliance AND oracle insufficiency. Fixing coverage is prerequisite to measuring behavioral compliance.

2. **Reflection debt accumulation during quiescent periods**

   The Feb 9-14 period had 5 improvement captures and 0 task sessions. These captures sat unprocessed for 5 days. The introspection hierarchy only runs when triggered -- during quiescent periods, observations accumulate without processing. The "cooldown reflection curve" identified by L0-feb9-14 (0-3h: friction observations, 12-24h: structural observations, 3+ days: design observations) is real but unserved by the current trigger model.

3. **Build failure patterns are well-characterized but not fully addressed**

   Three L0 passes over the Feb 8 epoch converged on precise data: 35.7% build failure rate, 100% retry rate, 100% of failures in single-repo builds (not cross-repo). Single-repo builds are vulnerable to stale dependencies; cross-repo builds flush stale state by rebuilding the full chain. #293 (build cache validation) is closed, suggesting the immediate fix was applied, but the underlying "upstream freshness check for single-repo builds" recommendation from L0-feb8 has no tracking.

### Emerging Best Practices

1. **Triple-pass L0 convergence on quantitative claims**

   The Feb 8 epoch received three L0 analyses. Each pass refined the prior: L0-1 estimated 50% build failure rate, L0-2 corrected to 31%, L0-3 measured 35.7% precisely and identified the single-repo vs cross-repo split. This convergence pattern demonstrates that quantitative claims improve with repeated analysis. However, three passes on the same epoch is expensive. Future L0s should aim for L0-3-level precision on the first pass.

2. **The cooldown reflection curve is a real phenomenon**

   Improvement captures follow a predictable temporal pattern post-session: immediate friction observations (0-3h), structural observations (12-24h), forward-looking design observations (3+ days). This is useful for interpretation: a capture made 5 days post-session is likely a design insight, not a friction report.

3. **Issue closure velocity improved dramatically**

   All 12 issues from this period's L0s (#284-#295) are now closed, as are all 5 new issues (#343-#347). The previous L1 identified 8 open unresolved improvement captures. The issue pipeline is functioning: observations -> L0 findings -> issues -> closure. The gap is no longer in issue creation but in whether closures represent actual fixes vs. documentation-only "fixes."

### Trend Analysis

**Getting better:**
- Issue pipeline throughput: all 17 issues from the introspection hierarchy are closed
- Block-wait compliance: 0% violation (the behavioral success story)
- Build failure understanding: root causes are well-characterized (single-repo fragility, cache staleness)
- L0 quantitative precision: third-pass convergence demonstrates learning
- Feature velocity: the Feb 14-15 period produced Epics #316 (OSforGFF), #323 (dep graph QoL), #308 (ChebyshevCircles), #333 (self-documentation) -- significant scope expansion of the SBS toolchain

**Getting worse:**
- Oracle-first compliance: 100% violation, three consecutive epochs, zero improvement despite documentation
- Tagger contamination: now identified at three scales (within-epoch, cross-temporal, cross-task)
- Session duration: 11-hour maximum, trending upward from the Feb 8 epoch's multi-hour sessions
- Scope expansion during execution: Feb 15 task started narrow, expanded mid-flight

**Stable:**
- Improvement capture rate: ~0.42/entry during friction sessions, near-zero during clean sessions (healthy bimodal distribution)
- Agent-orchestrator role boundaries: documented but still violated (#343); the documentation exists but enforcement does not
- Self-improve infrastructure: finding documents still require manual file writes (#291 closed but the underlying limitation persists)

## Systemic Findings

### S1: The observation infrastructure has a fundamental granularity mismatch

The tagger, oracle, and epoch summary system were designed for moderate sessions (10-30 entries, one task per session). Real usage increasingly involves:
- Multi-task sessions sharing one Claude Code session
- 11-hour sessions with 8+ entries and scope expansion
- Quiescent periods with captures but no tasks

All three patterns produce misleading data through the tagger (contaminated signals), oracle (stale coverage), and epoch summaries (aggregation across dissimilar work). This is not a bug in any single component -- it's an architectural mismatch between the observation model (session-scoped) and the workflow reality (task-scoped, variable duration).

**Fix direction:** Scope observation to skill/task boundaries rather than Claude Code session boundaries. The `sls_skill_start`/`sls_skill_end` lifecycle events provide natural observation windows that don't suffer from session-level contamination.

### S2: The documentation-enforcement graduation pipeline (#292) needs to move from concept to implementation

The previous L1 proposed this pipeline. It was logged as #292 and closed. But the underlying problem it addresses is more acute than ever:
- oracle-first: documented 7+ days, 100% violation
- MCP-first for builds: documented, still violated
- orchestrator plan approval: documented, still violated

Closing #292 without implementing the actual pipeline created a false sense of resolution. The pipeline concept needs concrete implementation: a scoring system that tracks protocol compliance over time and automatically flags protocols for guardrail implementation when compliance remains below threshold after a defined documentation period.

### S3: The introspection hierarchy lacks quiescent-period triggers

The Feb 9-14 period demonstrated that improvement captures accumulate during idle periods without processing. The hierarchy triggers on task sessions (L0 after every session) but has no mechanism for idle-period processing. This creates "reflection debt" -- observations that are never synthesized until the next active session triggers L0.

**Fix direction:** Auto-trigger L0 when 3+ improvement captures accumulate without a corresponding task session within 48 hours.

## Behavioral Findings

### B1: Orchestrator continues to blur the orchestration/execution boundary

Three distinct manifestations:
1. Direct skill lifecycle invocation instead of plan approval (#343)
2. Hand-summarizing agent research output instead of forwarding it (#346)
3. Entering "doing mode" without recognizing it

The CLAUDE.md documentation on "Doing Mode Detection" and "Orchestrator role" exists but these violations continue. The behavioral pattern is: under time pressure or during complex tasks, the orchestrator shortcuts the delegation model and acts directly. This is rational behavior (faster in the moment) but creates downstream costs (lost context, corrupted state, reduced agent effectiveness).

### B2: Agents default to bash over MCP tools for familiar operations

Captures 1770602096 and 1771121194 both identify the same pattern: agents use raw bash for build, serve, and graph generation operations that have MCP wrappers. The root cause is likely training data -- bash commands are more familiar than MCP tool calls, and agents reach for what they know. Documentation has not changed this behavior.

### B3: The triple-capture threshold works as a behavioral internalization signal

The block-wait lesson required 3 captures across 3 sessions before it stuck. The oracle-first lesson has been captured once and documented once but hasn't stuck. This suggests a practical heuristic: lessons that have been captured 3+ times are ready for behavioral internalization; lessons captured fewer times may need more reinforcement before they can be expected to change behavior without tooling.

## Tooling Findings

### T1: Tagger needs skill-scoped signal evaluation windows

The cross-task tag leakage (#347) and cross-temporal contamination (L0-feb9-14) both stem from session-scoped evaluation. The fix is well-defined: reset signal evaluation at skill boundaries (`sls_skill_start`/`sls_skill_end`). This is a focused change to the tagger that would significantly improve archive data quality.

### T2: Oracle concept index needs coverage expansion

The oracle doesn't index `vscode-lean4` or `LeanArchitect RPC` modules. Adding these is prerequisite to distinguishing "agents skip oracle because they don't know about it" from "agents skip oracle because it can't answer their query." The oracle regeneration was recommended by the previous L1; it's unclear whether it was performed.

### T3: `sls_task` reentry guard needs to block same-skill reentry (#344)

The fix is 3 lines of code (change the guard from `current_skill != "task"` to `current_skill is not None`). This prevents the most severe data integrity issue discovered in this period. If crash recovery is needed, add an explicit `resume=True` parameter.

### T4: Single-repo builds need upstream freshness verification

The Feb 8 L0 third pass identified that 100% of build failures were single-repo builds. Cross-repo builds never failed because they flush stale state. Adding a pre-build check that compares current submodule SHAs against last-build SHAs would prevent the entire class of single-repo cache staleness failures.

## Priority Stack

1. **T3: Fix `sls_task` reentry guard** -- 3-line fix, prevents data integrity corruption. Highest impact-to-effort ratio.

2. **T1: Skill-scoped tagger evaluation** -- Fixes signal contamination at all three scales (within-epoch, cross-temporal, cross-task). Improves all downstream analysis quality.

3. **S2: Implement the compliance tracking pipeline** -- The documentation-enforcement concept is validated (oracle-first: 7+ days documented, 0% compliance). Without actual compliance measurement and automated escalation, documented protocols are effectively advisory. This is the structural fix for the entire class of "documented but not followed" findings.

4. **T2: Oracle coverage expansion** -- Prerequisite to measuring whether oracle-first enforcement would actually help. Currently cannot distinguish non-compliance from oracle insufficiency.

5. **S3: Quiescent-period L0 triggers** -- Prevents reflection debt accumulation. Low effort, moderate impact on introspection completeness.

6. **T4: Upstream freshness check for single-repo builds** -- Prevents the most common build failure class. Medium effort, high impact on developer experience.

7. **S1: Task-scoped observation model** -- The architectural redesign. Highest impact but highest effort. Items 1-2 are tactical fixes for the worst symptoms; this is the strategic fix.

## Actions Taken

- Issues logged: **0 new issues**
  - All patterns identified in this L1 are already covered by existing (closed) issues or are systemic recommendations that don't map cleanly to a single implementation issue
  - The most actionable items (T3: reentry guard, T1: tagger scoping) already have issues (#344, #347) that were logged during the L0 phase and subsequently closed
  - If closures were documentation-only rather than implementation fixes, those issues should be reopened rather than duplicated

## Recommendations for L2

1. **Audit issue closures for implementation vs documentation-only resolution.** This L1 identified that all 17 issues from the introspection hierarchy are closed, but the underlying patterns persist (oracle-first at 100% violation, tagger contamination at 3 scales, orchestrator role confusion). L2 should verify whether closed issues represent actual code/tooling changes or just documentation additions.

2. **Quantify the cost of documentation-without-enforcement.** The oracle-first protocol has been documented for 7+ days with 0% compliance. Estimate the token cost of manual exploration vs oracle queries across the Feb 8-15 period. This provides a concrete ROI for building compliance tooling (#292 pipeline).

3. **Evaluate whether the introspection hierarchy is generating diminishing returns.** This L1 analyzed 5 L0 documents covering 3 analyses of the same Feb 8 epoch (with progressive refinement), 1 analysis of a quiescent period, and 1 analysis of Feb 15. The Feb 8 epoch has been analyzed three times at L0 and twice at L1. Is continued re-analysis productive, or should the hierarchy enforce "no more than 2 L0 passes per epoch"?

4. **Track the block-wait success as a template.** The block-wait lesson is the only documented-protocol that achieved 0% violation. Understanding why (immediate failure consequences + triple-capture + behavioral change) provides a template for designing other protocols. L2 should formalize this as a "protocol internalization model."

5. **Assess feature velocity against infrastructure debt.** The Feb 14-15 period produced 4 epics worth of new feature work (#308, #316, #323, #333). Meanwhile, 17 infrastructure issues were closed. L2 should evaluate whether the infrastructure improvements are keeping pace with the expanding feature surface, or whether the gap is widening.
